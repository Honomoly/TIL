{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 분류: 이진 분류 예제\n",
    "\n",
    "- 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 데이터셋\n",
    "- 케라스 데이터 셋  \n",
    "- 인터넷 영화 데이터베이스(Internet Movie Database)로부터 가져온 \n",
    "- 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용\n",
    "\n",
    "\n",
    "- 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 \n",
    "- 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있음\n",
    "\n",
    "- 전처리되어 있음 : 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있음\n",
    "- 각 숫자는 사전에 있는 고유한 단어를 나타냄\n",
    "\n",
    "\n",
    "어휘 사전 (사전)\n",
    "- 모든 단어에 고유한 번호 부여\n",
    "- 텍스트 데이터를 다룰 때 기본적으로 수행하는 전처리 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영화 리뷰 분류 과정\n",
    "- (1) 데이터셋 준비\n",
    "- (2) 모델링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data / test_data : 리뷰 목록\n",
    "- 각 리뷰는 단어 인덱스의 리스트\n",
    "- 단어 시퀀스가 인코딩된 것\n",
    "\n",
    "train_labels / test_labels (레이블 값)\n",
    "- 0 : 부정\n",
    "- 1: 긍정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]\n",
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(x) for x in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인덱스와 단어 확인\n",
    "- 리뷰 데이터 하나를 원래 영어 단어로 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "# key가 단어, value가 숫자이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구조 변경\n",
    "reversed_word_index = dict([(val, key) for key, val in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<???> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <???> is an amazing actor and now the same being director <???> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <???> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <???> to the two little boy's that played the <???> of norman and paul they were just brilliant children are often left out of the <???> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "# 참고로 0, 1, 2 인덱스는 리뷰의 시작 특성을 나타내기에 3을 뺀 값을 인덱스로 한다\n",
    "decoded_review = ' '.join([reversed_word_index.get(i-3, '<???>') for i in train_data[0]])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "\n",
    "- 신경망에 숫자 리스트를 입력으로 사용할 수 없기 때문에\n",
    "- 리스트를 텐서로 변경 : 벡터로 변환 [0, 1, 1, 0, 1, ... 0, 1]\n",
    "- 멀티-핫 인코딩 방법 사용해서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_test = np.array([[1, 2], [3, 4], [5, 6, 7]]) 차원수가 안맞아서 오류\n",
    "a_test = np.array([[1, 4], [2, 7], [4, 5, 8]], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_test을 인코딩한 값을 넣을 배열 미리 생성\n",
    "result = np.zeros((len(a_test), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, d in enumerate(a_test):\n",
    "    result[i, d] += 1\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패딩 (Padding)\n",
    "- 문장의 길이를 나타내는 배열의 크기를 동일하게 맞추는 작업  \n",
    "- 길이가 전부 동일한 문서들에 대하여 하나의 행렬로 인식하고  \n",
    "- 한꺼번에 묶어서 처리  \n",
    "- 각 문자의(문서)의 길이가 서로 다른 경우  \n",
    "- 동일한 길이로 맞추는 빈 부분은 0을 채움  \n",
    "- 예 : [1, 2]와 [1, 3, 4] 길이가 다른 배열을 길이 5로 동일하게 만들기   \n",
    "    - [1, 1, 0, 0, 0]  \n",
    "    - [1, 0, 1, 1, 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sequences, dim=10000):\n",
    "    arr = np.zeros((len(sequences), dim))\n",
    "    for idx, seq in enumerate(sequences):\n",
    "        arr[idx, seq] += 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorize(train_data)\n",
    "X_test = vectorize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 검증용을 따로 준비\n",
    "X_val = X_train[:20000]\n",
    "X_tr = X_train[20000:]\n",
    "y_val = y_train[:20000]\n",
    "y_tr = y_train[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 모델링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1) 모델 설정  \n",
    "- (2) 모델 컴파일  \n",
    "- (3) 모델 학습(실행)  \n",
    "- (4) 평가 결과 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 13:41:12.190848: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-12-04 13:41:12.190899: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-12-04 13:41:12.190908: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-12-04 13:41:12.190967: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-04 13:41:12.190984: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model_imdb = Sequential()\n",
    "\n",
    "model_imdb.add(Dense(units=100, input_dim=10000, activation='linear'))\n",
    "model_imdb.add(Dense(units=10, activation='relu'))\n",
    "model_imdb.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# 컴파일\n",
    "model_imdb.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   1/5000 [..............................] - ETA: 27:52 - loss: 0.6957 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 13:41:14.016973: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.3483 - accuracy: 0.8545 - val_loss: 0.3152 - val_accuracy: 0.8740\n",
      "Epoch 2/3\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.2720 - accuracy: 0.8951 - val_loss: 0.3642 - val_accuracy: 0.8592\n",
      "Epoch 3/3\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.2124 - accuracy: 0.9213 - val_loss: 0.3689 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x282d27a50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imdb.fit(x=X_val, y=y_val, epochs=3, batch_size=4, validation_data=(X_tr, y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 검증 데이터에 대한 손실과 정확도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장 및 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델을 훈련시킨 후에 이를 실전 환경에서 사용 \n",
    "- predict() 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEP_ENV",
   "language": "python",
   "name": "deepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
